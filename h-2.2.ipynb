{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33db522-cd75-430d-bf19-bf573d9c8b4a",
   "metadata": {},
   "source": [
    "# DA 210 -- Spring 2025 -- Homework 2.2 -- Professor Lavin\n",
    "\n",
    "## Directions \n",
    "\n",
    "This assignment is a little bit different from the others.\n",
    "\n",
    "1. Begin by creating a new repository under your account on Github.com. Name the repo `da-210-spring-2025-h-2.2` and select the option to add a `README.md` to the project.\n",
    "2. You can make the repo public or keep it private and add me as a collaborator (username `mjlavin80`)\n",
    "3. Clone the repository to your computer\n",
    "4. Working locally, set up your project with: copies of all GSS data files from H-2 and a Jupyter Notebook file called `h-2.2.ipynb`   \n",
    "5. Copy/paste the \"Load Data\" block and questions 1-4 below to your `h-2.2.ipynb` file. Make sure each question is in a separate markdown cell.\n",
    "6. Below each question, input your response in either a code cell or a markdown cell\n",
    "7. When you are finished, save your work, convert the Jupytext Notebook to .html format, and submit the `h-2.2.html` file on Canvas.\n",
    "8. Push your updated `da-210-spring-2025-h-2.2` repo to Github.com.\n",
    "\n",
    "__Reminders:__ \n",
    "\n",
    "- You are not permitted to get the answers from a classmate or to use Github Copilot, chatGPT, etc. on this homework. These exercises are for practice so, if you use outside help in a way that's not permitted, you are only cheating yourself out of a chance to learn and prepare for future quizzes and tests. \n",
    "- Working with an ARC tutor and visiting our TA's office hours are both permitted, but they should be provide advice and support, and you should not expect them to do your work for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2e07b1-7b8b-484e-8089-e494f72064bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# load sample csv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_gss_sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocuments/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_sample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# load rows counts of full data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m gss_full_row_counts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocuments/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_full_row_counts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_sample.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# load sample csv\n",
    "df_gss_sample = pd.read_csv('Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_sample.csv', index_col=0, low_memory=False, encoding='utf8') \n",
    "\n",
    "# load rows counts of full data\n",
    "gss_full_row_counts = pd.read_csv('Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/data/gss_full_row_counts.csv', index_col=0, low_memory=False, encoding='utf8')\n",
    "\n",
    "# load years per variable data\n",
    "gss_years_per_var = pd.read_csv('Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/meta/gss_data_years_per_var.csv', index_col=0, low_memory=False, encoding='utf8')\n",
    "\n",
    "# load data dictionary\n",
    "gss_data_dictionary =  pd.read_csv('Documents/DA-210/GitHub/da-210-spring-2025-h-2.2/gss/meta/gss_data_dictionary.csv', index_col=0, low_memory=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31f411-5a61-41cc-b505-99e5b0ced871",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "1. Working with `df_gss_sample`, create a variable called `mycols` that is a list of ten (10) column names that are related to one another in some way.\n",
    "2. Create a new variable called `df_gss_sample_ten_cols` that contains only the ten (10) columns in `mycols`.\n",
    "3. In a markdown cell below this question, explain how your variables are related to one another.\n",
    "\n",
    "__Hint__: to find related variables, look at the variable names, the 'var_doc_label' column in `gss_data_dictionary` and/or the GSS Data Explorer at https://gssdataexplorer.norc.org/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647980ef-2e52-4e6d-a0fb-07f9869f8591",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gss_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mycols \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudge\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredeemer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlover\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaster\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmother\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfather\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfriend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m df_gss_sample_ten_cols \u001b[38;5;241m=\u001b[39m df_gss_sample[mycols]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_gss_sample' is not defined"
     ]
    }
   ],
   "source": [
    "mycols = {'judge','redeemer', 'lover', 'master', 'mother', 'creator', 'father', 'spouse', 'friend', 'king'}\n",
    "df_gss_sample_ten_cols = df_gss_sample[mycols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c68d5-5244-4ce8-b543-429f2b22cf30",
   "metadata": {},
   "source": [
    "These 10 variables are related as they are the different ways that respondants chose to express their relationship with God. Each one represents a different way people view their relationship on God, and how they see them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b69cc-fa54-4b16-a198-7fc9dd75d012",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "In a markdown cell below this question, address the following:\n",
    "\n",
    "- How does `gss_sample` relate to `gss_full_row_counts`? If we assume `gss_sample` is a sample of a larger dataset of GSS data, why would we want some information about the full rows counts from the dataset? \n",
    "- Generally speaking, what information is contained in the `gss_years_per_var` and `gss_data_dictionary` DataFrames? How can we use these sources to better understand our sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a3b53-fc80-4e9d-9f2e-ccbcb54c4d17",
   "metadata": {},
   "source": [
    "gss_sample contains a subset of the full information contained in gss_full_row_counts. We may want only some of this information for better understanding in analysis, and to see how the data sample is represented. We could find different patterns that tell a story about some sort of bias or ambiguity that appears in the data, and plan accordingly from here. The information contained in the gss_years_var contains less information than the gss_data_dictionary, and simply the year in which the information was collected. gss_data_dictionary contains extended information about the responses in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1d28b-aae2-4ed3-b0a2-abc31d026fb1",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "In a code cell below this question, use the `value_counts` method to display a count for each unique value found in the `zodiac` column of `df_gss_sample`. __Display the result as a `DataFrame`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03a6adda-70d9-4e4a-9d5e-c6fd6fec5222",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_gss_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DataFrame \u001b[38;5;241m=\u001b[39m df_gss_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzodiac\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(DataFrame)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_gss_sample' is not defined"
     ]
    }
   ],
   "source": [
    "DataFrame = df_gss_sample['zodiac'].value_counts()\n",
    "print(DataFrame) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995dee76-2fd5-4251-86c8-438de7b4357a",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "In a code cell below this question, display a scatter plot depicting the `realinc` variable on one axis and the respondents occupational prestige score based on the 2010 Census occupation classification. \n",
    "\n",
    "__Hint:__ Pandas has some simple plotting options built into it, and the Seaborn library is designed to accept a pandas DataFrame as an input, sort of like (but not as good as) ggplot in R. Here are some resources on Pandas and Seaborn plots:\n",
    "\n",
    "- Built-in plots: https://pandas.pydata.org/docs/user_guide/10min.html#plotting\n",
    "- Seaborn scatter plot: https://seaborn.pydata.org/generated/seaborn.scatterplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "555bc724-b956-4ab9-b0e1-6cc43d72a79f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (4103070794.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.title('Family's Income vs. Residents Occupational Prestige')\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "#residents occupational prestive score 'prestg10'\n",
    "import matplotlib.pyplot as plt\n",
    "gss_sample.csv(kind = 'scatter', x = 'realinc', y = 'prestg10') \n",
    "plt.title('Family's Income vs. Residents Occupational Prestige') \n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Occupational Prestige Score') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
